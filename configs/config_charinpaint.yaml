# train on combination of all datas
data:
  target: "src.trainers.WrappedDataModule"
  batch_size: 4
  scene_data: ocr-dataset/
  synth_data: ocr-dataset/synth/
  train:
    size: 256
    max_num: 2000000 # diffly choose this number
    augconf:
      synth:
        center: 0.1
        pad: false
      scene:
        expand_mask:
          center_mask: 0.6
          additional_mask: 0.4
        crop:
          mask_image_ratio: 15
        rotate:
          cat_prob: [1, 0, 0]
          angle_list: [-15, -30, -45, -60, -90, 15, 30, 45, 60, 90] 
          rotate_range: 90

    dataconfs:
      ArT:
        type: scene
        label_path: ${data.scene_data}/ArT/train_labels.json
        image_dir: ${data.scene_data}/ArT/train_images/

      COCO:
        type: scene
        label_path: ${data.scene_data}/COCO/cocotext.v2.json
        image_dir: ${data.scene_data}/COCO/train2014/
  
      TextOCR:
        type: scene
        label_path: ${data.scene_data}/TextOCR/TextOCR_0.1_train.json
        image_dir: ${data.scene_data}/TextOCR/train_images/
      
      Synthtiger:
        type: synth
        label_path: ${data.synth_data}/train_data.csv 
        image_dir: ${data.synth_data}/
        style_mode: same-same
        use_textbbox: false
        style_dropout: [0.5, 0.5]
        rand_mask_text: true

  
  validation:
    size: 256
    # max_num: 6400 # diffly choose this number
    augconf:
      synth:
        center: 1.
        pad: false
      scene:
        expand_mask:
          center_mask: 0.
          additional_mask: 0.
        crop:
          mask_image_ratio: 30
        rotate:
          cat_prob: [1, 0, 0]
          angle_list: [-15, -30, -45, -60, -90, 15, 30, 45, 60, 90] 
          rotate_range: 90

    dataconfs:
      ArT:
        type: scene
        label_path: ${data.scene_data}/ArT/val_split.json
        image_dir: ${data.scene_data}/ArT/train_images/
      
      COCO:
        type: scene
        label_path: ${data.scene_data}/COCO/cocotext.v2.val.json
        image_dir: ${data.scene_data}/COCO/train2014/

      TextOCR:
       type: scene
       label_path: ${data.scene_data}/TextOCR/TextOCR_0.1_val.json
       image_dir: ${data.scene_data}/TextOCR/train_images/

model:
  source: raw
  target: "src.trainers.CharInpaintModelWrapper"
  pretrained_model_path: runwayml/stable-diffusion-inpainting
  loss_type: MaskMSELoss
  loss_alpha: 5
  base_learning_rate: 5.0e-5
  precision: 16
  weight_decay: 0.0
  adam_epsilon: 1.0e-8
  freeze_char_embedder: false
  optimize_vae: false
  vae:

  tokenizer:
    model_max_length: 20
  char_tokenizer:
    pretrained_path: checkpoints/chartokenizer
    pad_token: " "
    unk_token: " "
    model_max_length: 20
  char_embedder: 
    vocab_size: 95 # by default
    embedding_dim: 32
    max_length: 20
    padding_idx: 0
    attention_head_dim: 2
  unet:
    attention_head_dim: {"text": 8, "char": 2}
    cross_attention_dim: {"text": 768, "char": 32}
  noise_scheduler: diffusers.DDIMScheduler

lightning:
  logger: 
  callbacks: 
    checkpoint_callback:
      params:
        save_top_k: -1
    image_logger:
      target: "src.trainers.CharInpaintImageLogger"
      params:
        # train_batch_frequency: 2400
        # valid_batch_frequency: 500
        train_batch_frequency: 2
        valid_batch_frequency: 2
        disable_wandb: true
        generation_kwargs:
          num_inference_steps: 30
          num_sample_per_image: 3
          guidance_scale: 7.5
          seed: 42
    
    # NOTE: Download pretrained ABINet model from https://github.com/FangShancheng/ABINet.git and 
    #       put model checkpoints in checkpoints/abinet to use this callback
    # ocracc_logger:
    #   target: "src.trainers.OCRAccLogger"
    #   params:
    #     train_eval_conf:
    #       size: 256
    #       augconf: ${data.validation.augconf}
    #       max_num: 5
    #       dataconfs:
    #         TextOCR:
    #           type: scene
    #           label_path: ${data.scene_data}/TextOCR/TextOCR_0.1_train.json
    #           image_dir: ${data.scene_data}/TextOCR/train_images/
    #           len_counter:
    #             eachnum: 10

    #     val_eval_conf:
    #       size: 256
    #       augconf: ${data.validation.augconf}
    #       max_num: 5
    #       dataconfs:
    #         TextOCR:
    #           type: scene
    #           label_path: ${data.scene_data}/TextOCR/TextOCR_0.1_val.json
    #           image_dir: ${data.scene_data}/TextOCR/train_images/
    #           max_num: 1000
    #     base_log_dir: ${base_log_dir}/ocrlogs # will be set in code

  trainer:
    accelerator: gpu
    devices: [0, 1, 2, 3, 4, 5, 6, 7]
    strategy: ddp
    amp_backend: native
    log_every_n_steps: 16 # this is global step
    precision: 16
    max_epochs: 15
    check_val_every_n_epoch: 1
    accumulate_grad_batches: 8
    gradient_clip_val: 3.
    gradient_clip_algorithm: norm
    benchmark: true